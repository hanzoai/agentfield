name: Memory Performance Metrics

on:
  pull_request:
    paths:
      - 'sdk/python/**'
      - 'sdk/go/**'
      - 'sdk/typescript/**'
      - 'control-plane/**'
      - '.github/workflows/memory-metrics.yml'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

jobs:
  python-metrics:
    name: Python SDK Metrics
    runs-on: ubuntu-latest
    outputs:
      metrics: ${{ steps.run-tests.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: sdk/python
        run: |
          python -m pip install --upgrade pip
          pip install .[dev]

      - name: Run memory performance tests
        id: run-tests
        working-directory: sdk/python
        run: |
          # Run tests and capture output
          python -m pytest tests/test_memory_performance.py -v --tb=short 2>&1 | tee test_output.txt

          # Extract key metrics for the summary
          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Test | Status | Memory |" >> $GITHUB_OUTPUT
          echo "|------|--------|--------|" >> $GITHUB_OUTPUT

          # Parse test results
          if grep -q "passed" test_output.txt; then
            PASSED=$(grep -oP '\d+(?= passed)' test_output.txt | tail -1)
            echo "| Memory Tests | ‚úÖ ${PASSED} passed | Optimized |" >> $GITHUB_OUTPUT
          else
            echo "| Memory Tests | ‚ùå Failed | - |" >> $GITHUB_OUTPUT
          fi
          echo "EOF" >> $GITHUB_OUTPUT

  go-metrics:
    name: Go SDK Metrics
    runs-on: ubuntu-latest
    outputs:
      metrics: ${{ steps.run-tests.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Run memory performance tests
        id: run-tests
        working-directory: sdk/go
        run: |
          # Run tests and capture output
          go test -v ./agent/... -run "InMemoryBackendMemoryPerformance|MemoryPerformanceReport" 2>&1 | tee test_output.txt

          # Extract metrics
          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Test | Heap (MB) | Per Iter (KB) |" >> $GITHUB_OUTPUT
          echo "|------|-----------|---------------|" >> $GITHUB_OUTPUT

          # Parse InMemoryBackend metrics
          if grep -q "Heap Alloc:" test_output.txt; then
            HEAP=$(grep "Heap Alloc:" test_output.txt | head -1 | grep -oP '[\d.]+(?= MB)')
            PER_ITER=$(grep "Per Iteration:" test_output.txt | head -1 | grep -oP '[\d.]+(?= KB)')
            echo "| InMemoryBackend | ${HEAP:-N/A} | ${PER_ITER:-N/A} |" >> $GITHUB_OUTPUT
          fi

          # Parse ClearScope reduction
          if grep -q "Reduction:" test_output.txt; then
            REDUCTION=$(grep "Reduction:" test_output.txt | grep -oP '[\d.]+(?=%)')
            echo "| ClearScope | - | ${REDUCTION}% freed |" >> $GITHUB_OUTPUT
          fi
          echo "EOF" >> $GITHUB_OUTPUT

  typescript-metrics:
    name: TypeScript SDK Metrics
    runs-on: ubuntu-latest
    outputs:
      metrics: ${{ steps.run-tests.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        working-directory: sdk/typescript
        run: npm install

      - name: Run memory performance tests
        id: run-tests
        working-directory: sdk/typescript
        run: |
          # Run tests and capture output
          npm test -- tests/memory_performance.test.ts 2>&1 | tee test_output.txt

          # Extract metrics
          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Test | Memory | Per Unit |" >> $GITHUB_OUTPUT
          echo "|------|--------|----------|" >> $GITHUB_OUTPUT

          # Parse agent creation metrics
          if grep -q "Agent Creation Memory:" test_output.txt; then
            MEM=$(grep "Agent Creation Memory:" test_output.txt | grep -oP '[\d.]+(?= MB|KB)' | head -1)
            UNIT=$(grep "Agent Creation Memory:" test_output.txt | grep -oP '(MB|KB)' | head -1)
            PER=$(grep "Per Agent:" test_output.txt | grep -oP '[\d.]+(?= KB)')
            echo "| Agent Creation | ${MEM} ${UNIT} | ${PER} KB/agent |" >> $GITHUB_OUTPUT
          fi

          # Parse registration metrics
          if grep -q "Per Registration:" test_output.txt; then
            PER_REG=$(grep "Per Registration:" test_output.txt | grep -oP '[\d.]+(?= KB)')
            echo "| Registration | - | ${PER_REG} KB/each |" >> $GITHUB_OUTPUT
          fi

          # Parse memory leak check
          if grep -q "Memory Leak Check:" test_output.txt; then
            LEAK=$(grep "Memory Leak Check:" test_output.txt | grep -oP '[\d.]+(?= MB)')
            echo "| Leak Check | ${LEAK} MB growth | ‚úÖ |" >> $GITHUB_OUTPUT
          fi
          echo "EOF" >> $GITHUB_OUTPUT

  control-plane-metrics:
    name: Control Plane Metrics
    runs-on: ubuntu-latest
    outputs:
      metrics: ${{ steps.run-tests.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Run benchmarks
        id: run-tests
        working-directory: control-plane
        run: |
          # Run any memory-related benchmarks
          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Component | Status |" >> $GITHUB_OUTPUT
          echo "|-----------|--------|" >> $GITHUB_OUTPUT

          # Check if tests pass
          if go build ./...; then
            echo "| Build | ‚úÖ Success |" >> $GITHUB_OUTPUT
          else
            echo "| Build | ‚ùå Failed |" >> $GITHUB_OUTPUT
          fi

          # Run any existing benchmarks
          if go test -v ./internal/... -run "Benchmark" -bench=. -benchtime=1s 2>&1 | head -50 | tee bench_output.txt; then
            echo "| Benchmarks | ‚úÖ Completed |" >> $GITHUB_OUTPUT
          fi
          echo "EOF" >> $GITHUB_OUTPUT
        continue-on-error: true

  post-metrics-comment:
    name: Post Metrics Comment
    runs-on: ubuntu-latest
    needs: [python-metrics, go-metrics, typescript-metrics, control-plane-metrics]
    if: github.event_name == 'pull_request'
    steps:
      - name: Post PR Comment
        uses: actions/github-script@v7
        with:
          script: |
            const pythonMetrics = `${{ needs.python-metrics.outputs.metrics }}`;
            const goMetrics = `${{ needs.go-metrics.outputs.metrics }}`;
            const tsMetrics = `${{ needs.typescript-metrics.outputs.metrics }}`;
            const cpMetrics = `${{ needs.control-plane-metrics.outputs.metrics }}`;

            const body = `## üìä Memory Performance Metrics

            This PR includes changes that may affect memory usage. Here are the benchmark results:

            ### Python SDK
            ${pythonMetrics || '> No metrics available'}

            ### Go SDK
            ${goMetrics || '> No metrics available'}

            ### TypeScript SDK
            ${tsMetrics || '> No metrics available'}

            ### Control Plane
            ${cpMetrics || '> No metrics available'}

            ---
            <details>
            <summary>‚ÑπÔ∏è About these metrics</summary>

            These metrics are collected from memory performance tests that validate:
            - **ExecutionState**: Memory cleared after completion/error/cancel
            - **ResultCache**: Bounded by max size with LRU eviction
            - **HTTP Sessions**: Shared session pool for connection reuse
            - **SSE Buffer**: Limited to prevent unbounded growth

            Target: **< 10 KB per iteration** for most operations
            </details>

            *Generated by memory-metrics workflow*`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const existingComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('Memory Performance Metrics')
            );

            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body
              });
            }
