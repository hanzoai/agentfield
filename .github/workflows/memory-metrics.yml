name: SDK Performance Metrics

on:
  pull_request:
    paths:
      - 'sdk/python/**'
      - 'sdk/go/**'
      - 'sdk/typescript/**'
      - 'control-plane/**'
      - '.github/workflows/memory-metrics.yml'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

jobs:
  python-metrics:
    name: Python SDK
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.summary.outputs.status }}
      metrics: ${{ steps.summary.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: sdk/python
        run: |
          python -m pip install --upgrade pip
          pip install .[dev]

      - name: Run linter
        id: lint
        working-directory: sdk/python
        run: |
          if ruff check . 2>&1; then
            echo "lint_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "lint_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run tests with timing
        id: tests
        working-directory: sdk/python
        run: |
          START=$(date +%s.%N)
          python -m pytest tests/ --ignore=tests/integration -q 2>&1 | tee test_output.txt
          END=$(date +%s.%N)
          DURATION=$(echo "$END - $START" | bc)

          if grep -q "passed" test_output.txt; then
            PASSED=$(grep -oP '\d+(?= passed)' test_output.txt | tail -1)
            echo "test_status=‚úÖ" >> $GITHUB_OUTPUT
            echo "test_passed=${PASSED}" >> $GITHUB_OUTPUT
          else
            echo "test_status=‚ùå" >> $GITHUB_OUTPUT
            echo "test_passed=0" >> $GITHUB_OUTPUT
          fi
          echo "test_duration=${DURATION}" >> $GITHUB_OUTPUT

      - name: Run memory performance tests
        id: memory
        working-directory: sdk/python
        run: |
          python -m pytest tests/test_memory_performance.py -v 2>&1 | tee memory_output.txt

          # Extract memory metrics
          if grep -q "PASSED" memory_output.txt; then
            echo "memory_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "memory_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi

      - name: Run request performance benchmark
        id: perf
        working-directory: sdk/python
        run: |
          python -c "
          import time
          import statistics
          from agentfield.client import AgentFieldClient
          from agentfield.execution_state import ExecutionState
          from agentfield.result_cache import ResultCache
          from agentfield.async_config import AsyncConfig

          # Benchmark ExecutionState creation
          times = []
          for _ in range(1000):
              start = time.perf_counter()
              state = ExecutionState(
                  execution_id='test',
                  target='agent.reasoner',
                  input_data={'key': 'value' * 100}
              )
              state.set_result({'output': 'done'})
              times.append((time.perf_counter() - start) * 1000)

          avg_ms = statistics.mean(times)
          p99_ms = sorted(times)[int(len(times) * 0.99)]

          print(f'exec_state_avg={avg_ms:.3f}')
          print(f'exec_state_p99={p99_ms:.3f}')

          # Benchmark ResultCache
          config = AsyncConfig()
          cache = ResultCache(config)
          times = []
          for i in range(5000):
              start = time.perf_counter()
              cache.set(f'key_{i}', {'data': 'x' * 500})
              cache.get(f'key_{i}')
              times.append((time.perf_counter() - start) * 1000)

          cache_avg = statistics.mean(times)
          cache_p99 = sorted(times)[int(len(times) * 0.99)]

          print(f'cache_avg={cache_avg:.3f}')
          print(f'cache_p99={cache_p99:.3f}')
          " 2>&1 | tee perf_output.txt

          EXEC_AVG=$(grep "exec_state_avg" perf_output.txt | cut -d= -f2)
          EXEC_P99=$(grep "exec_state_p99" perf_output.txt | cut -d= -f2)
          CACHE_AVG=$(grep "cache_avg" perf_output.txt | cut -d= -f2)
          CACHE_P99=$(grep "cache_p99" perf_output.txt | cut -d= -f2)

          echo "exec_avg=${EXEC_AVG}" >> $GITHUB_OUTPUT
          echo "exec_p99=${EXEC_P99}" >> $GITHUB_OUTPUT
          echo "cache_avg=${CACHE_AVG}" >> $GITHUB_OUTPUT
          echo "cache_p99=${CACHE_P99}" >> $GITHUB_OUTPUT

      - name: Generate summary
        id: summary
        run: |
          # Overall status
          if [[ "${{ steps.tests.outputs.test_status }}" == "‚úÖ" && "${{ steps.memory.outputs.memory_status }}" == "‚úÖ" ]]; then
            echo "status=‚úÖ PASS" >> $GITHUB_OUTPUT
          else
            echo "status=‚ùå FAIL" >> $GITHUB_OUTPUT
          fi

          # Metrics table
          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Metric | Value | Status |" >> $GITHUB_OUTPUT
          echo "|--------|-------|--------|" >> $GITHUB_OUTPUT
          echo "| Lint | - | ${{ steps.lint.outputs.lint_status }} |" >> $GITHUB_OUTPUT
          echo "| Tests | ${{ steps.tests.outputs.test_passed }} passed | ${{ steps.tests.outputs.test_status }} |" >> $GITHUB_OUTPUT
          echo "| Test Duration | ${{ steps.tests.outputs.test_duration }}s | - |" >> $GITHUB_OUTPUT
          echo "| Memory Tests | - | ${{ steps.memory.outputs.memory_status }} |" >> $GITHUB_OUTPUT
          echo "| ExecutionState (avg) | ${{ steps.perf.outputs.exec_avg }}ms | - |" >> $GITHUB_OUTPUT
          echo "| ExecutionState (p99) | ${{ steps.perf.outputs.exec_p99 }}ms | - |" >> $GITHUB_OUTPUT
          echo "| Cache ops (avg) | ${{ steps.perf.outputs.cache_avg }}ms | - |" >> $GITHUB_OUTPUT
          echo "| Cache ops (p99) | ${{ steps.perf.outputs.cache_p99 }}ms | - |" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  go-metrics:
    name: Go SDK
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.summary.outputs.status }}
      metrics: ${{ steps.summary.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Run linter
        id: lint
        working-directory: sdk/go
        run: |
          if go vet ./... 2>&1; then
            echo "lint_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "lint_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run tests
        id: tests
        working-directory: sdk/go
        run: |
          START=$(date +%s.%N)
          go test -v ./... 2>&1 | tee test_output.txt
          END=$(date +%s.%N)
          DURATION=$(echo "$END - $START" | bc)

          if grep -q "PASS" test_output.txt && ! grep -q "FAIL" test_output.txt; then
            PASSED=$(grep -c "--- PASS" test_output.txt || echo "0")
            echo "test_status=‚úÖ" >> $GITHUB_OUTPUT
            echo "test_passed=${PASSED}" >> $GITHUB_OUTPUT
          else
            echo "test_status=‚ùå" >> $GITHUB_OUTPUT
            echo "test_passed=0" >> $GITHUB_OUTPUT
          fi
          echo "test_duration=${DURATION}" >> $GITHUB_OUTPUT

      - name: Run benchmarks
        id: bench
        working-directory: sdk/go
        run: |
          go test -bench=. -benchmem ./agent/... 2>&1 | tee bench_output.txt

          # Extract benchmark results
          SET_NS=$(grep "BenchmarkInMemoryBackendSet" bench_output.txt | awk '{print $3}' | head -1)
          GET_NS=$(grep "BenchmarkInMemoryBackendGet" bench_output.txt | awk '{print $3}' | head -1)
          SET_ALLOC=$(grep "BenchmarkInMemoryBackendSet" bench_output.txt | awk '{print $5}' | head -1)

          echo "set_ns=${SET_NS:-N/A}" >> $GITHUB_OUTPUT
          echo "get_ns=${GET_NS:-N/A}" >> $GITHUB_OUTPUT
          echo "set_alloc=${SET_ALLOC:-N/A}" >> $GITHUB_OUTPUT

      - name: Run memory tests
        id: memory
        working-directory: sdk/go
        run: |
          go test -v ./agent/... -run "MemoryPerformance" 2>&1 | tee memory_output.txt

          HEAP=$(grep "Heap Alloc:" memory_output.txt | head -1 | grep -oP '[\d.]+(?= MB)' || echo "N/A")
          REDUCTION=$(grep "Reduction:" memory_output.txt | grep -oP '[\d.]+(?=%)' || echo "N/A")

          echo "heap_mb=${HEAP}" >> $GITHUB_OUTPUT
          echo "reduction=${REDUCTION}" >> $GITHUB_OUTPUT

          if grep -q "PASS" memory_output.txt; then
            echo "memory_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "memory_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi

      - name: Generate summary
        id: summary
        run: |
          if [[ "${{ steps.tests.outputs.test_status }}" == "‚úÖ" && "${{ steps.memory.outputs.memory_status }}" == "‚úÖ" ]]; then
            echo "status=‚úÖ PASS" >> $GITHUB_OUTPUT
          else
            echo "status=‚ùå FAIL" >> $GITHUB_OUTPUT
          fi

          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Metric | Value | Status |" >> $GITHUB_OUTPUT
          echo "|--------|-------|--------|" >> $GITHUB_OUTPUT
          echo "| Lint (go vet) | - | ${{ steps.lint.outputs.lint_status }} |" >> $GITHUB_OUTPUT
          echo "| Tests | ${{ steps.tests.outputs.test_passed }} passed | ${{ steps.tests.outputs.test_status }} |" >> $GITHUB_OUTPUT
          echo "| Test Duration | ${{ steps.tests.outputs.test_duration }}s | - |" >> $GITHUB_OUTPUT
          echo "| Memory Tests | - | ${{ steps.memory.outputs.memory_status }} |" >> $GITHUB_OUTPUT
          echo "| Heap Usage | ${{ steps.memory.outputs.heap_mb }} MB | - |" >> $GITHUB_OUTPUT
          echo "| ClearScope Reduction | ${{ steps.memory.outputs.reduction }}% | - |" >> $GITHUB_OUTPUT
          echo "| Set op | ${{ steps.bench.outputs.set_ns }} ns/op | - |" >> $GITHUB_OUTPUT
          echo "| Get op | ${{ steps.bench.outputs.get_ns }} ns/op | - |" >> $GITHUB_OUTPUT
          echo "| Set alloc | ${{ steps.bench.outputs.set_alloc }} B/op | - |" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  typescript-metrics:
    name: TypeScript SDK
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.summary.outputs.status }}
      metrics: ${{ steps.summary.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        working-directory: sdk/typescript
        run: npm install

      - name: Run linter
        id: lint
        working-directory: sdk/typescript
        run: |
          if npm run lint 2>&1; then
            echo "lint_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "lint_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run tests
        id: tests
        working-directory: sdk/typescript
        run: |
          START=$(date +%s.%N)
          npm test 2>&1 | tee test_output.txt
          END=$(date +%s.%N)
          DURATION=$(echo "$END - $START" | bc)

          if grep -q "passed" test_output.txt; then
            PASSED=$(grep -oP '\d+(?= passed)' test_output.txt | tail -1)
            echo "test_status=‚úÖ" >> $GITHUB_OUTPUT
            echo "test_passed=${PASSED}" >> $GITHUB_OUTPUT
          else
            echo "test_status=‚ùå" >> $GITHUB_OUTPUT
            echo "test_passed=0" >> $GITHUB_OUTPUT
          fi
          echo "test_duration=${DURATION}" >> $GITHUB_OUTPUT

      - name: Run memory tests
        id: memory
        working-directory: sdk/typescript
        run: |
          npm test -- tests/memory_performance.test.ts 2>&1 | tee memory_output.txt

          AGENT_MEM=$(grep "Agent Creation Memory:" memory_output.txt | grep -oP '[\d.]+(?= MB)' || echo "N/A")
          PER_AGENT=$(grep "Per Agent:" memory_output.txt | grep -oP '[\d.]+(?= KB)' || echo "N/A")
          LEAK=$(grep "Memory Leak Check:" memory_output.txt | grep -oP '[\d.]+(?= MB)' || echo "N/A")

          echo "agent_mem=${AGENT_MEM}" >> $GITHUB_OUTPUT
          echo "per_agent=${PER_AGENT}" >> $GITHUB_OUTPUT
          echo "leak_growth=${LEAK}" >> $GITHUB_OUTPUT

          if grep -q "passed" memory_output.txt; then
            echo "memory_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "memory_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi

      - name: Generate summary
        id: summary
        run: |
          if [[ "${{ steps.tests.outputs.test_status }}" == "‚úÖ" && "${{ steps.memory.outputs.memory_status }}" == "‚úÖ" ]]; then
            echo "status=‚úÖ PASS" >> $GITHUB_OUTPUT
          else
            echo "status=‚ùå FAIL" >> $GITHUB_OUTPUT
          fi

          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Metric | Value | Status |" >> $GITHUB_OUTPUT
          echo "|--------|-------|--------|" >> $GITHUB_OUTPUT
          echo "| Lint | - | ${{ steps.lint.outputs.lint_status }} |" >> $GITHUB_OUTPUT
          echo "| Tests | ${{ steps.tests.outputs.test_passed }} passed | ${{ steps.tests.outputs.test_status }} |" >> $GITHUB_OUTPUT
          echo "| Test Duration | ${{ steps.tests.outputs.test_duration }}s | - |" >> $GITHUB_OUTPUT
          echo "| Memory Tests | - | ${{ steps.memory.outputs.memory_status }} |" >> $GITHUB_OUTPUT
          echo "| Agent Creation | ${{ steps.memory.outputs.agent_mem }} MB | - |" >> $GITHUB_OUTPUT
          echo "| Per Agent | ${{ steps.memory.outputs.per_agent }} KB | - |" >> $GITHUB_OUTPUT
          echo "| Leak Growth | ${{ steps.memory.outputs.leak_growth }} MB | - |" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  control-plane-metrics:
    name: Control Plane
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.summary.outputs.status }}
      metrics: ${{ steps.summary.outputs.metrics }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Build
        id: build
        working-directory: control-plane
        run: |
          START=$(date +%s.%N)
          if go build ./... 2>&1; then
            echo "build_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "build_status=‚ùå" >> $GITHUB_OUTPUT
          fi
          END=$(date +%s.%N)
          DURATION=$(echo "$END - $START" | bc)
          echo "build_duration=${DURATION}" >> $GITHUB_OUTPUT

      - name: Run linter
        id: lint
        working-directory: control-plane
        run: |
          if go vet ./... 2>&1; then
            echo "lint_status=‚úÖ" >> $GITHUB_OUTPUT
          else
            echo "lint_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Run tests
        id: tests
        working-directory: control-plane
        run: |
          START=$(date +%s.%N)
          go test -v ./... -short 2>&1 | tee test_output.txt || true
          END=$(date +%s.%N)
          DURATION=$(echo "$END - $START" | bc)

          if grep -q "PASS" test_output.txt; then
            PASSED=$(grep -c "--- PASS" test_output.txt || echo "0")
            echo "test_status=‚úÖ" >> $GITHUB_OUTPUT
            echo "test_passed=${PASSED}" >> $GITHUB_OUTPUT
          else
            echo "test_status=‚ö†Ô∏è" >> $GITHUB_OUTPUT
            echo "test_passed=0" >> $GITHUB_OUTPUT
          fi
          echo "test_duration=${DURATION}" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Generate summary
        id: summary
        run: |
          if [[ "${{ steps.build.outputs.build_status }}" == "‚úÖ" ]]; then
            echo "status=‚úÖ PASS" >> $GITHUB_OUTPUT
          else
            echo "status=‚ùå FAIL" >> $GITHUB_OUTPUT
          fi

          echo "metrics<<EOF" >> $GITHUB_OUTPUT
          echo "| Metric | Value | Status |" >> $GITHUB_OUTPUT
          echo "|--------|-------|--------|" >> $GITHUB_OUTPUT
          echo "| Build | ${{ steps.build.outputs.build_duration }}s | ${{ steps.build.outputs.build_status }} |" >> $GITHUB_OUTPUT
          echo "| Lint (go vet) | - | ${{ steps.lint.outputs.lint_status }} |" >> $GITHUB_OUTPUT
          echo "| Tests | ${{ steps.tests.outputs.test_passed }} passed | ${{ steps.tests.outputs.test_status }} |" >> $GITHUB_OUTPUT
          echo "| Test Duration | ${{ steps.tests.outputs.test_duration }}s | - |" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  post-metrics-comment:
    name: Post Report
    runs-on: ubuntu-latest
    needs: [python-metrics, go-metrics, typescript-metrics, control-plane-metrics]
    if: github.event_name == 'pull_request'
    steps:
      - name: Post PR Comment
        uses: actions/github-script@v7
        with:
          script: |
            const pythonStatus = `${{ needs.python-metrics.outputs.status }}`;
            const goStatus = `${{ needs.go-metrics.outputs.status }}`;
            const tsStatus = `${{ needs.typescript-metrics.outputs.status }}`;
            const cpStatus = `${{ needs.control-plane-metrics.outputs.status }}`;

            const pythonMetrics = `${{ needs.python-metrics.outputs.metrics }}`;
            const goMetrics = `${{ needs.go-metrics.outputs.metrics }}`;
            const tsMetrics = `${{ needs.typescript-metrics.outputs.metrics }}`;
            const cpMetrics = `${{ needs.control-plane-metrics.outputs.metrics }}`;

            // Determine overall status
            const allPass = [pythonStatus, goStatus, tsStatus, cpStatus].every(s => s.includes('‚úÖ'));
            const overallStatus = allPass ? '‚úÖ All Checks Passed' : '‚ö†Ô∏è Some Checks Need Attention';

            const body = `## üìä SDK Performance Report

            ### Quick Status
            | Component | Status |
            |-----------|--------|
            | Python SDK | ${pythonStatus} |
            | Go SDK | ${goStatus} |
            | TypeScript SDK | ${tsStatus} |
            | Control Plane | ${cpStatus} |
            | **Overall** | **${overallStatus}** |

            ---

            <details>
            <summary><b>üêç Python SDK Details</b></summary>

            ${pythonMetrics || '> No metrics available'}

            </details>

            <details>
            <summary><b>üîµ Go SDK Details</b></summary>

            ${goMetrics || '> No metrics available'}

            </details>

            <details>
            <summary><b>üìò TypeScript SDK Details</b></summary>

            ${tsMetrics || '> No metrics available'}

            </details>

            <details>
            <summary><b>üéõÔ∏è Control Plane Details</b></summary>

            ${cpMetrics || '> No metrics available'}

            </details>

            ---

            <details>
            <summary>üìñ Metric Definitions</summary>

            | Metric | Description | Target |
            |--------|-------------|--------|
            | **Lint** | Static code analysis | ‚úÖ No warnings |
            | **Tests** | Unit test pass rate | ‚úÖ 100% |
            | **Memory Tests** | Memory leak/efficiency | ‚úÖ Pass |
            | **ExecutionState** | State creation latency | < 1ms avg |
            | **Cache ops** | Get/Set latency | < 0.1ms avg |
            | **Heap Usage** | Memory footprint | < 1MB |
            | **ClearScope** | Memory freed on clear | > 90% |
            | **Leak Growth** | Memory after 500 cycles | < 10MB |

            </details>

            *Generated by SDK Performance workflow ‚Ä¢ [View logs](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})*`;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const existingComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('SDK Performance Report')
            );

            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body
              });
            }
